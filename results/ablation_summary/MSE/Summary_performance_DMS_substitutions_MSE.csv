Model_rank,Model_name,Model type,Average_MSE,Bootstrap_standard_error_MSE,Average_MSE_fold_random_5,Average_MSE_fold_modulo_5,Average_MSE_fold_contiguous_5,Function_Activity,Function_Binding,Function_Expression,Function_OrganismalFitness,Function_Stability,Low_MSA_depth,Medium_MSA_depth,High_MSA_depth,Taxa_Human,Taxa_Other_Eukaryote,Taxa_Prokaryote,Taxa_Virus,References,Model details
1,Kermut (EVE),,0.608,0.007,0.412,0.682,0.731,0.639,0.87,0.564,0.67,0.299,0.445,0.668,0.541,0.489,0.524,0.529,0.514,,
2,Kermut (GEMME),,0.609,0.005,0.416,0.682,0.728,0.639,0.885,0.557,0.669,0.296,0.441,0.672,0.541,0.484,0.521,0.528,0.526,,
3,Kermut,Embedding,0.611,0.0,0.42,0.683,0.73,0.64,0.903,0.558,0.665,0.289,0.421,0.694,0.546,0.485,0.519,0.509,0.568,"<a href='https://www.biorxiv.org/content/10.1101/2024.05.28.596219v1'>Groth, P. M., Kerrn, M. H., Olsen, L., Salomon, J., Boomsma, W. (2024).  Kermut: Composite kernel regression for protein variant effects</a>",Kermut GP
4,Kermut (no Hellinger),,0.616,0.002,0.421,0.691,0.735,0.651,0.906,0.557,0.669,0.295,0.425,0.707,0.551,0.498,0.52,0.514,0.58,,
5,Kermut (TranceptEVE),,0.618,0.004,0.42,0.693,0.741,0.649,0.907,0.558,0.676,0.299,0.436,0.691,0.553,0.499,0.527,0.524,0.551,,
6,Kermut (VESPA),,0.62,0.008,0.424,0.698,0.737,0.642,0.925,0.562,0.668,0.3,0.437,0.695,0.546,0.505,0.525,0.519,0.542,,
7,Kermut (ESM-IF1),,0.63,0.006,0.424,0.708,0.757,0.663,0.928,0.571,0.705,0.283,0.442,0.711,0.554,0.5,0.534,0.536,0.551,,
8,Kermut (no p),,0.634,0.006,0.436,0.704,0.761,0.651,0.923,0.584,0.682,0.327,0.449,0.718,0.572,0.514,0.539,0.54,0.6,,
9,Kermut (ProteinMPNN),,0.639,0.005,0.429,0.718,0.769,0.671,0.932,0.575,0.713,0.301,0.457,0.714,0.568,0.512,0.542,0.551,0.566,,
10,Kermut (const. mean),,0.639,0.005,0.429,0.718,0.77,0.672,0.932,0.575,0.71,0.304,0.456,0.714,0.569,0.514,0.544,0.55,0.567,,
11,Kermut (no Hellinger/p),,0.644,0.008,0.436,0.722,0.775,0.672,0.933,0.586,0.688,0.343,0.46,0.742,0.583,0.538,0.546,0.551,0.617,,
12,Kermut (no distance),,0.652,0.006,0.426,0.743,0.789,0.696,0.965,0.599,0.702,0.301,0.438,0.755,0.576,0.509,0.55,0.538,0.617,,
13,Kermut (no global),,0.676,0.008,0.492,0.744,0.791,0.673,0.926,0.622,0.718,0.44,0.531,0.743,0.631,0.581,0.603,0.612,0.627,,
14,Kermut (no m),,0.684,0.012,0.46,0.769,0.825,0.712,0.993,0.626,0.734,0.358,0.484,0.795,0.617,0.563,0.571,0.582,0.706,,
15,ProteinNPT,Embedding,0.714,0.02,0.461,0.817,0.863,0.726,1.101,0.607,0.767,0.368,0.509,0.789,0.647,0.589,0.596,0.62,0.64,"<a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ProteinNPT Model
16,MSA Transformer Embeddings,Embedding,0.737,0.024,0.543,0.811,0.856,0.721,1.168,0.625,0.764,0.405,0.509,0.819,0.685,0.62,0.618,0.618,0.685,"[1] Original model: <a href='http://proceedings.mlr.press/v139/rao21a.html'>Rao, R., Liu, J., Verkuil, R., Meier, J., Canny, J.F., Abbeel, P., Sercu, T., & Rives, A. (2021). MSA Transformer. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",MSA Transformer Embeddings
17,"Kermut (no m, const. mean)",,0.74,0.012,0.483,0.832,0.906,0.783,1.069,0.656,0.803,0.39,0.54,0.852,0.666,0.632,0.623,0.639,0.716,,
18,Tranception Embeddings,Embedding,0.797,0.028,0.495,0.872,1.024,0.839,1.166,0.662,0.793,0.525,0.63,0.816,0.755,0.711,0.716,0.703,0.676,"[1] Original model: <a href='https://proceedings.mlr.press/v162/notin22a.html'>Notin, P., Dias, M., Frazer, J., Marchena-Hurtado, J., Gomez, A.N., Marks, D.S., & Gal, Y. (2022). Tranception: Protein Fitness Prediction with Autoregressive Transformers and Inference-time Retrieval. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",Tranception Embeddings
19,ESM-1v Embeddings,Embedding,0.804,0.034,0.54,0.895,0.977,0.824,1.337,0.648,0.755,0.456,0.545,0.943,0.708,0.712,0.654,0.661,0.724,"[1] Original model: <a href='https://proceedings.neurips.cc/paper/2021/hash/f51338d736f95dd42427296047067694-Abstract.html'>Meier, J., Rao, R., Verkuil, R., Liu, J., Sercu, T., & Rives, A. (2021). Language models enable zero-shot prediction of the effects of mutations on protein function. NeurIPS.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ESM-1v Embeddings
20,TranceptEVE + One-Hot Encodings,One-hot Encoding,0.891,0.023,0.744,0.943,0.987,0.798,1.29,0.803,0.81,0.756,0.763,0.908,0.854,0.846,0.789,0.837,0.815,"[1] Original model: <a href='https://www.biorxiv.org/content/10.1101/2022.12.07.519495v1?rss=1'>Notin, P., Van Niekerk, L., Kollasch, A., Ritter, D., Gal, Y. & Marks, D.S. &  (2022). TranceptEVE: Combining Family-specific and Family-agnostic Models of Protein Sequences for Improved Fitness Prediction. NeurIPS, LMRL workshop.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",TranceptEVE + One-Hot Encodings
21,MSA_Transformer + One-Hot Encodings,One-hot Encoding,0.901,0.023,0.746,0.963,0.994,0.818,1.314,0.797,0.821,0.756,0.763,0.94,0.861,0.847,0.8,0.845,0.813,"[1] Original model: <a href='http://proceedings.mlr.press/v139/rao21a.html'>Rao, R., Liu, J., Verkuil, R., Meier, J., Canny, J.F., Abbeel, P., Sercu, T., & Rives, A. (2021). MSA Transformer. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",MSA Transformer + One-Hot Encodings
22,DeepSequence + One-Hot Encodings,One-hot Encoding,0.911,0.02,0.767,0.969,0.998,0.842,1.216,0.859,0.845,0.793,0.793,0.944,0.884,0.879,0.824,0.855,0.875,"<a href='https://www.nature.com/articles/s41587-021-01146-5'>Hsu, C., Nisonoff, H., Fannjiang, C. et al. Learning protein fitness models from evolutionary and assay-labeled data. Nat Biotechnol 40, 1114–1122 (2022). https://doi.org/10.1038/s41587-021-01146-5</a>",DeepSequence + One-Hot Encodings
23,Tranception + One-Hot Encodings,One-hot Encoding,0.916,0.025,0.767,0.963,1.019,0.834,1.349,0.805,0.827,0.765,0.774,0.936,0.876,0.864,0.81,0.859,0.821,"[1] Original model: <a href='https://proceedings.mlr.press/v162/notin22a.html'>Notin, P., Dias, M., Frazer, J., Marchena-Hurtado, J., Gomez, A.N., Marks, D.S., & Gal, Y. (2022). Tranception: Protein Fitness Prediction with Autoregressive Transformers and Inference-time Retrieval. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",Tranception + One-Hot Encodings
24,ESM-1v + One-Hot Encodings,One-hot Encoding,0.918,0.016,0.763,0.981,1.01,0.866,1.283,0.814,0.845,0.783,0.769,0.995,0.883,0.865,0.822,0.868,0.874,"[1] Original model: <a href='https://proceedings.neurips.cc/paper/2021/hash/f51338d736f95dd42427296047067694-Abstract.html'>Meier, J., Rao, R., Verkuil, R., Liu, J., Sercu, T., & Rives, A. (2021). Language models enable zero-shot prediction of the effects of mutations on protein function. NeurIPS.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ESM-1v + One-Hot Encodings
25,One-Hot Encodings,One-hot Encoding,1.077,0.019,0.89,1.153,1.188,1.03,1.369,0.984,1.053,0.949,1.004,1.094,1.035,1.033,1.002,1.063,0.982,"<a href='https://www.nature.com/articles/s41587-021-01146-5'>Hsu, C., Nisonoff, H., Fannjiang, C. et al. Learning protein fitness models from evolutionary and assay-labeled data. Nat Biotechnol 40, 1114–1122 (2022). https://doi.org/10.1038/s41587-021-01146-5</a>",One-Hot Encodings
