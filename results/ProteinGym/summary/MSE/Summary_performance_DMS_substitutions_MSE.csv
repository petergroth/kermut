Model_rank,Model_name,Model type,Average_MSE,Bootstrap_standard_error_MSE,Average_MSE_fold_random_5,Average_MSE_fold_modulo_5,Average_MSE_fold_contiguous_5,Function_Activity,Function_Binding,Function_Expression,Function_OrganismalFitness,Function_Stability,Low_MSA_depth,Medium_MSA_depth,High_MSA_depth,Taxa_Human,Taxa_Other_Eukaryote,Taxa_Prokaryote,Taxa_Virus,References,Model details
1,ProteinNPT,Embedding,0.67,0.0,0.424,0.774,0.812,0.697,0.935,0.591,0.758,0.368,0.518,0.684,0.65,0.538,0.603,0.618,0.652,"<a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ProteinNPT Model
2,MSA Transformer Embeddings,Embedding,0.732,0.015,0.551,0.805,0.839,0.729,1.059,0.67,0.794,0.405,0.521,0.786,0.706,0.589,0.657,0.619,0.716,"[1] Original model: <a href='http://proceedings.mlr.press/v139/rao21a.html'>Rao, R., Liu, J., Verkuil, R., Meier, J., Canny, J.F., Abbeel, P., Sercu, T., & Rives, A. (2021). MSA Transformer. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",MSA Transformer Embeddings
3,ESM-1v Embeddings,Embedding,0.746,0.026,0.518,0.838,0.881,0.801,1.023,0.667,0.782,0.456,0.555,0.803,0.725,0.633,0.668,0.661,0.757,"[1] Original model: <a href='https://proceedings.neurips.cc/paper/2021/hash/f51338d736f95dd42427296047067694-Abstract.html'>Meier, J., Rao, R., Verkuil, R., Liu, J., Sercu, T., & Rives, A. (2021). Language models enable zero-shot prediction of the effects of mutations on protein function. NeurIPS.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ESM-1v Embeddings
4,Tranception Embeddings,Embedding,0.769,0.031,0.503,0.833,0.972,0.814,1.08,0.639,0.788,0.525,0.635,0.781,0.757,0.724,0.712,0.703,0.717,"[1] Original model: <a href='https://proceedings.mlr.press/v162/notin22a.html'>Notin, P., Dias, M., Frazer, J., Marchena-Hurtado, J., Gomez, A.N., Marks, D.S., & Gal, Y. (2022). Tranception: Protein Fitness Prediction with Autoregressive Transformers and Inference-time Retrieval. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",Tranception Embeddings
5,TranceptEVE + One-Hot Encodings,One-hot Encoding,0.857,0.018,0.702,0.914,0.954,0.794,1.107,0.798,0.828,0.756,0.768,0.822,0.851,0.788,0.792,0.844,0.824,"[1] Original model: <a href='https://www.biorxiv.org/content/10.1101/2022.12.07.519495v1?rss=1'>Notin, P., Van Niekerk, L., Kollasch, A., Ritter, D., Gal, Y. & Marks, D.S. &  (2022). TranceptEVE: Combining Family-specific and Family-agnostic Models of Protein Sequences for Improved Fitness Prediction. NeurIPS, LMRL workshop.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",TranceptEVE + One-Hot Encodings
6,MSA_Transformer + One-Hot Encodings,One-hot Encoding,0.868,0.013,0.707,0.936,0.961,0.811,1.136,0.801,0.836,0.756,0.767,0.858,0.855,0.787,0.807,0.849,0.812,"[1] Original model: <a href='http://proceedings.mlr.press/v139/rao21a.html'>Rao, R., Liu, J., Verkuil, R., Meier, J., Canny, J.F., Abbeel, P., Sercu, T., & Rives, A. (2021). MSA Transformer. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",MSA Transformer + One-Hot Encodings
7,DeepSequence + One-Hot Encodings,One-hot Encoding,0.875,0.017,0.727,0.937,0.961,0.832,1.045,0.845,0.859,0.793,0.796,0.868,0.88,0.829,0.823,0.861,0.873,"<a href='https://www.nature.com/articles/s41587-021-01146-5'>Hsu, C., Nisonoff, H., Fannjiang, C. et al. Learning protein fitness models from evolutionary and assay-labeled data. Nat Biotechnol 40, 1114–1122 (2022). https://doi.org/10.1038/s41587-021-01146-5</a>",DeepSequence + One-Hot Encodings
8,Tranception + One-Hot Encodings,One-hot Encoding,0.877,0.022,0.722,0.928,0.981,0.833,1.134,0.808,0.843,0.765,0.779,0.844,0.872,0.8,0.815,0.863,0.826,"[1] Original model: <a href='https://proceedings.mlr.press/v162/notin22a.html'>Notin, P., Dias, M., Frazer, J., Marchena-Hurtado, J., Gomez, A.N., Marks, D.S., & Gal, Y. (2022). Tranception: Protein Fitness Prediction with Autoregressive Transformers and Inference-time Retrieval. ICML.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",Tranception + One-Hot Encodings
9,ESM-1v + One-Hot Encodings,One-hot Encoding,0.877,0.018,0.728,0.941,0.962,0.846,1.094,0.805,0.857,0.783,0.771,0.896,0.879,0.81,0.822,0.869,0.866,"[1] Original model: <a href='https://proceedings.neurips.cc/paper/2021/hash/f51338d736f95dd42427296047067694-Abstract.html'>Meier, J., Rao, R., Verkuil, R., Liu, J., Sercu, T., & Rives, A. (2021). Language models enable zero-shot prediction of the effects of mutations on protein function. NeurIPS.</a> [2] Extension: <a href='https://openreview.net/forum?id=AwzbQVuDBk'>Notin, P., Weitzman, R., Marks, D. S., & Gal, Y. (2023). ProteinNPT: Improving protein property prediction and design with non-parametric transformers. Thirty-Seventh Conference on Neural Information Processing Systems</a>",ESM-1v + One-Hot Encodings
10,One-Hot Encodings,One-hot Encoding,1.038,0.017,0.853,1.118,1.144,1.025,1.184,0.986,1.045,0.949,1.004,1.009,1.031,0.972,1.004,1.064,0.984,"<a href='https://www.nature.com/articles/s41587-021-01146-5'>Hsu, C., Nisonoff, H., Fannjiang, C. et al. Learning protein fitness models from evolutionary and assay-labeled data. Nat Biotechnol 40, 1114–1122 (2022). https://doi.org/10.1038/s41587-021-01146-5</a>",One-Hot Encodings
11,kermutBH_oh,,12688578629335.805,17011365511342.61,6982827575138.908,15932338315148.793,15150569997719.715,65.652,63442893146562.1,0.969,49.743,0.56,4.215,27756265751621.094,46.78,1.347,7401670867149.86,5.888,0.431,,
